{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Paragraph_Ranker.ipynb",
      "provenance": [],
      "mount_file_id": "1sQe0knrvC5EX7IpCsFzjU6B2i061jCOO",
      "authorship_tag": "ABX9TyO6YJ2ZPIyy9wj6jQPbsNg0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aliebi/Master/blob/main/Paragraph_Selection/Paragraph_Ranker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKVEi-FLzy2C"
      },
      "source": [
        "### DATASET\n",
        "Download Dataset from ali97ebrahimi if there isn't train and test file clone code from github and run it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tReNd5WJ2TGf"
      },
      "source": [
        "!mkdir /content/input_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klYQQ7gA3XSo",
        "outputId": "d64c3958-7019-4a5a-b601-7241a8b8d625"
      },
      "source": [
        "cd /content/input_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/input_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzBkQ2bbzqwL",
        "outputId": "6cfaa9e7-c45a-43a3-9ec8-92f4466b161d"
      },
      "source": [
        "#train\n",
        "!gdown --id 1Y496rEF1sLXKWZb1w6XqXn5r6jtZ_ap0\n",
        "#dev\n",
        "!gdown --id 1-5ztVQ8SFZantmZtdBMywUoieRAz2bnb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Y496rEF1sLXKWZb1w6XqXn5r6jtZ_ap0\n",
            "To: /content/input_data/hotpot_train.csv\n",
            "672MB [00:05, 112MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-5ztVQ8SFZantmZtdBMywUoieRAz2bnb\n",
            "To: /content/input_data/hotpot_dev.csv\n",
            "54.5MB [00:00, 206MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ1e1wciz6C6"
      },
      "source": [
        "# !git clone https://github.com/aliebi/Master.git\n",
        "# run conver2csv "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9q5Wg4C0HrZ"
      },
      "source": [
        "### Paragraph_Ranker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxPVhk4A2ipA"
      },
      "source": [
        "# write model name and date for create output file \n",
        "!mkdir /content/drive/MyDrive/Paragraph_Ranker/Roberta_large_27-6-2021"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTU1D7Um3_6_",
        "outputId": "092d810a-0ff1-40bb-c984-71027e3cdbde"
      },
      "source": [
        "cd /content/drive/MyDrive/Paragraph_Ranker/Roberta_large_27-6-2021"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Paragraph_Ranker/Roberta_large_27-6-2021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5fwNNr60GeA",
        "outputId": "f0dc5f99-cfd0-4b51-b256-60309c2c7615"
      },
      "source": [
        "!git clone https://github.com/aliebi/Master.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Master'...\n",
            "remote: Enumerating objects: 43, done.\u001b[K\n",
            "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 43 (delta 5), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (43/43), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsIKf3fv2Fu9"
      },
      "source": [
        "# change input and output address in preprocess.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hziZbe-e0muZ",
        "outputId": "02c642ee-0c94-4c22-bcdd-62a9f2ce539e"
      },
      "source": [
        "cd /content/drive/MyDrive/Paragraph_Ranker/Roberta_large_27-6-2021/Master/Paragraph_Selection/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Paragraph_Ranker/Roberta_large_27-6-2021/Master/Paragraph_Selection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0GpzXnq0tPx",
        "outputId": "189b8eed-d241-457a-e791-f7676ec7d793"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mcheckpoints\u001b[0m/   \u001b[01;34mfigures\u001b[0m/              \u001b[01;34mpredictions\u001b[0m/   train_info.csv\n",
            "eval_info.csv  \u001b[01;34mparagraph_selection\u001b[0m/  preprocess.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1DZX70-0yMR"
      },
      "source": [
        "! chmod +rx preprocess.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDFOGYeb0z7h",
        "outputId": "6242c3c1-85a7-476b-d3ff-055abe749a49"
      },
      "source": [
        "!pip install boto3\n",
        "!pip install tensorboardX\n",
        "!pip install transformers\n",
        "!pip install SentencePiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/de/807c75923e84530b8a94003d761bcea33ebd5469b3d56c1141208360f39f/boto3-1.17.101-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 25.1MB/s \n",
            "\u001b[?25hCollecting botocore<1.21.0,>=1.20.101\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/76/f67a56460eba1997dd89b6b34b68150da1cf8cba0f5161cc4326383b4240/botocore-1.20.101-py2.py3-none-any.whl (7.7MB)\n",
            "\u001b[K     |████████████████████████████████| 7.7MB 36.9MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.3MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/64/43575537846896abac0b15c3e5ac678d787a4021e906703f1766bfb8ea11/urllib3-1.26.6-py2.py3-none-any.whl (138kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 61.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.101->boto3) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.101->boto3) (1.15.0)\n",
            "\u001b[31mERROR: requests 2.23.0 has requirement urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you'll have urllib3 1.26.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed boto3-1.17.101 botocore-1.20.101 jmespath-0.10.0 s3transfer-0.4.2 urllib3-1.26.6\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/36/2b147652c40c3a858efa0afbf7b8236fae968e88ff530511a4cfa299a506/tensorboardX-2.3-py2.py3-none-any.whl (124kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 30.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.12.4)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (57.0.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.3\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/d5/c6c23ad75491467a9a84e526ef2364e523d45e2b0fae28a7cbe8689e7e84/transformers-4.8.1-py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 29.6MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 39.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 50.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/aa/4ef5aa67a9a62505db124a5cb5262332d1d4153462eb8fd89c9fa41e5d92/urllib3-1.25.11-py2.py3-none-any.whl (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 57.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: huggingface-hub, tokenizers, sacremoses, transformers, urllib3\n",
            "  Found existing installation: urllib3 1.26.6\n",
            "    Uninstalling urllib3-1.26.6:\n",
            "      Successfully uninstalled urllib3-1.26.6\n",
            "Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.1 urllib3-1.25.11\n",
            "Collecting SentencePiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 34.8MB/s \n",
            "\u001b[?25hInstalling collected packages: SentencePiece\n",
            "Successfully installed SentencePiece-0.1.96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTJSJ78H5SaD",
        "outputId": "dd25dafd-3060-4cf0-fda0-9e569412a7cb"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jun 27 19:54:57 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1ry7kWl1I-5",
        "outputId": "29918508-0db7-42d9-9864-667178817dc8"
      },
      "source": [
        "! ./preprocess.sh --data_dir /content/input_data  --output_dir /content/drive/MyDrive/Paragraph_Ranker/Roberta_large_27-6-2021 --ckpt_dir /content/drive/MyDrive/Paragraph_Ranker/Roberta_large_27-6-2021"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
            "06/27/2021 20:09:58 - INFO - __main__ -   n_gpu: 1 Grad_Accum_steps: 1 Batch_size: 32\n",
            "06/27/2021 20:09:59 - INFO - filelock -   Lock 140298045436880 acquired on /root/.cache/huggingface/transformers/fe616facc71d8e3afc69de3edac76bf1e4a0a741e80d9a99a2cc6a9a8f5f74b5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 26.2MB/s]\n",
            "06/27/2021 20:09:59 - INFO - filelock -   Lock 140298045436880 released on /root/.cache/huggingface/transformers/fe616facc71d8e3afc69de3edac76bf1e4a0a741e80d9a99a2cc6a9a8f5f74b5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
            "06/27/2021 20:09:59 - INFO - filelock -   Lock 140297877887888 acquired on /root/.cache/huggingface/transformers/6f8b3f5095b6f44f5c75cee3c56b971b3208b08132ba2f9fb775a4a7b7140942.4f2213f5603276adf12967b32e4444c0f187f34ca4f8b22a65f03e13514589e9.lock\n",
            "Downloading: 100% 27.0/27.0 [00:00<00:00, 42.0kB/s]\n",
            "06/27/2021 20:09:59 - INFO - filelock -   Lock 140297877887888 released on /root/.cache/huggingface/transformers/6f8b3f5095b6f44f5c75cee3c56b971b3208b08132ba2f9fb775a4a7b7140942.4f2213f5603276adf12967b32e4444c0f187f34ca4f8b22a65f03e13514589e9.lock\n",
            "06/27/2021 20:09:59 - INFO - filelock -   Lock 140297877886288 acquired on /root/.cache/huggingface/transformers/81840ac426bf0d690bfb69a4ec7d706e8853d8ab309e7decb6b72ab939d6682e.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
            "Downloading: 100% 466k/466k [00:00<00:00, 42.3MB/s]\n",
            "06/27/2021 20:09:59 - INFO - filelock -   Lock 140297877886288 released on /root/.cache/huggingface/transformers/81840ac426bf0d690bfb69a4ec7d706e8853d8ab309e7decb6b72ab939d6682e.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
            "06/27/2021 20:09:59 - INFO - filelock -   Lock 140297877886160 acquired on /root/.cache/huggingface/transformers/7d1569a4df2372d67341bda716bce4e3edf3e3ffadb97251bc4b6b35d459f624.57c13443a51769ce892714c93bb3ee3952bad66d7d9662d9de382b808377c3f8.lock\n",
            "Downloading: 100% 666/666 [00:00<00:00, 996kB/s]\n",
            "06/27/2021 20:09:59 - INFO - filelock -   Lock 140297877886160 released on /root/.cache/huggingface/transformers/7d1569a4df2372d67341bda716bce4e3edf3e3ffadb97251bc4b6b35d459f624.57c13443a51769ce892714c93bb3ee3952bad66d7d9662d9de382b808377c3f8.lock\n",
            "06/27/2021 20:09:59 - INFO - filelock -   Lock 140297877555920 acquired on /root/.cache/huggingface/transformers/aed576b8aec823c870feda40d60bd803ac8e40056ecb7d7f43dd0b2bfd82e373.db390a2059e53ead2bb00e1a2f8cd50b0a47e1969d180cd70339ec3f6f29dce1.lock\n",
            "Downloading: 100% 440M/440M [00:08<00:00, 52.0MB/s]\n",
            "06/27/2021 20:10:08 - INFO - filelock -   Lock 140297877555920 released on /root/.cache/huggingface/transformers/aed576b8aec823c870feda40d60bd803ac8e40056ecb7d7f43dd0b2bfd82e373.db390a2059e53ead2bb00e1a2f8cd50b0a47e1969d180cd70339ec3f6f29dce1.lock\n",
            "Some weights of the model checkpoint at google/electra-base-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias']\n",
            "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-base-discriminator and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "06/27/2021 20:10:21 - INFO - __main__ -   LOOKING AT /content/input_data/hotpot_train.csv\n",
            " 59% 43574/73700 [01:42<01:09, 430.76it/s]Traceback (most recent call last):\n",
            "  File \"paragraph_selection/train.py\", line 291, in <module>\n",
            "    eval_examples, label_list, args.max_seq_length, tokenizer, verbose=False)\n",
            "  File \"paragraph_selection/train.py\", line 80, in convert_examples_to_features\n",
            "    tokens_b = tokenizer.tokenize(example.text_b)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py\", line 362, in tokenize\n",
            "    tokenized_text = split_on_tokens(no_split_token, text)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py\", line 356, in split_on_tokens\n",
            "    for token in tokenized_text\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py\", line 356, in <genexpr>\n",
            "    for token in tokenized_text\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/bert/tokenization_bert.py\", line 224, in _tokenize\n",
            "    for token in self.basic_tokenizer.tokenize(text, never_split=self.all_special_tokens):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/bert/tokenization_bert.py\", line 409, in tokenize\n",
            "    token = self._run_strip_accents(token)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/bert/tokenization_bert.py\", line 423, in _run_strip_accents\n",
            "    if cat == \"Mn\":\n",
            "KeyboardInterrupt\n",
            " 59% 43574/73700 [01:42<01:10, 425.13it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}